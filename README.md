# I. Setup
After setting up the URDF code and adding physical properties such as mass and inertia,  Gazebo is used to launch the vehicle model as follows:
<p align="center">
  <img src="https://github.com/user-attachments/assets/439273b4-7d11-4c4f-b4f8-a831c5aeb4df" width="450" height="300" alt="image" />
  <br />
  <em> Figure 1. 4WD mobile robot in simulation</em>
</p>
My simulated enviroment is the factory where there are a lot of obstacles and spaces for robot to 3D mapping and navigate 
<p align="center">
  <img src="https://github.com/user-attachments/assets/fdcd94ea-6cf3-4d26-808e-d76d2968b5da" width="805" height="450" alt="image" />
  <br />
  <em> Figure 2. Simulated factory in Gazebo </em>
</p>

# II. 3D Mapping
RTAB-Map (Real-Time Appearance-Based Mapping) is a graph-based SLAM approach being used in this project. Appearance-based SLAM means that the algorithm uses data collected from visual sensors to localize the robot and build a map of the environment. During the SLAM process using an RGB-D camera such as the Orbbec Astra, the system utilizes multiple ROS nodes to collect and process sensor data in real time in order to build a 3D map of the environment and localize the robot.

<div style="display: flex; justify-content: center; gap: 20px; margin: auto; width: fit-content;">
  <img src="https://github.com/user-attachments/assets/7d9a7789-15b1-4a67-be19-04d02838551a" width="389" height="220" alt="image" />
  <img src="https://github.com/user-attachments/assets/712a502c-0936-4876-81e7-2255b4a0fbd8" width="389" height="220" alt="image" />
</div>
<p align="center"><em>Figure 3. RTAB-Map S showing 3D Mapping with point clouds.</em></p>
During the processing of 3D point cloud data, especially when collected from sensors such as depth cameras or LiDAR, the amount of data is often large and dense. This can pose challenges for real-time processing, storage, and visualization. To address this issue, a common approach that is applied is voxelizing. After voxelizing, the new point cloud was reduced by nearly seven times compared to the original, while the resulting map still preserved the key features of the original map.

# III. Depth Camera and 2D LiDAR Fusion Algorithm
The algorithm aims to fuse data from a 2D LiDAR sensor and a depth camera to accurately determine the positions of detected objects in the environment. These positions are then used to display markers of the objects on the map generated by SLAM. The ultimate goal is to enhance the robot's spatial awareness and support object-tracking tasks.
<div style="display: flex; justify-content: center; gap: 20px; margin: auto; width: fit-content;">
  <img src="https://github.com/user-attachments/assets/74ec4f56-8845-4b77-87f4-b95cc16ba154" width="389" height="220" alt="image" />
  <img src="https://github.com/user-attachments/assets/9a6b48f9-a18c-4bc0-8a74-1d19d1b73185" width="389" height="220" alt="image" />
</div>
<p align="center"><em>Figure 4. Marker visualization from fused LiDAR and depth camera data.</em></p>
Observation: During the algorithm's processing, the marker's coordinates are slightly offset from the detected object. However, as the person moves, the marker continues to follow the person's trajectory. 

# IV. Using WebSocket for Image Transmission
In autonomous robotic applications, detecting and monitoring critical objects such as people and fire plays a vital role, especially in scenarios involving patrol, security, or rescue operations. The system presented in this document integrates the YOLOv8 object detection algorithm with ROS2 to identify and track objects in real time. Images are cropped according to the bounding boxes of the detected objects using the OpenCV library and then transmitted via the WebSocket protocol for remote monitoring.
<div style="display: flex; justify-content: center; gap: 20px; margin: auto; width: fit-content;">
  <img src="https://github.com/user-attachments/assets/c7368a67-8206-4e71-8266-a644caad8b04" width="389" height="220" alt="image" />
  <img src="https://github.com/user-attachments/assets/983b504a-036d-4492-b786-d66c144ae932" width="389" height="220" alt="image" />
</div>
<p align="center"><em>Figure 5. Real-time object detection and image transmission using WebSocket.</em></p>


